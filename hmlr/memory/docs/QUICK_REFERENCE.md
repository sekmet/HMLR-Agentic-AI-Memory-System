# Memory System - Quick Reference

**Last Updated:** October 10, 2025  
**Phase 2 Complete:** Retrieval & Metadata Extraction âœ…

---

## ğŸš€ Quick Start Integration

```python
# Add to main.py imports
from memory.retrieval.crawler import LatticeCrawler
from memory.retrieval.intent_analyzer import IntentAnalyzer
from memory.metadata_extractor import MetadataExtractor, MEMORY_SYSTEM_PROMPT

# Initialize (in main() function)
crawler = LatticeCrawler(storage, max_days_back=7)
intent_analyzer = IntentAnalyzer()
metadata_extractor = MetadataExtractor(fallback_to_simple=True)
```

---

## ğŸ” Usage Pattern (Full Flow)

```python
# 1. Analyze intent
intent = intent_analyzer.analyze(user_query)

# 2. Retrieve context
today = datetime.now().strftime("%Y-%m-%d")
context = crawler.retrieve_context(intent, today, max_results=5)

# 3. Build enhanced prompt
prompt = MEMORY_SYSTEM_PROMPT + "\n\n"
if context.contexts:
    prompt += "[MEMORY CONTEXT]:\n"
    for ctx in context.contexts[:3]:
        prompt += f"- {ctx['day_id']}: {ctx.get('context', '')[:100]}\n"
prompt += f"\nUser: {user_query}"

# 4. Call LLM
full_response = llm.chat(prompt)

# 5. Parse response
user_reply, metadata = metadata_extractor.parse_response(full_response)

# 6. Show user clean reply (metadata hidden)
print(f"Assistant: {user_reply}")

# 7. Save turn with metadata
conversation_mgr.log_turn(session_id, user_query, user_reply, metadata['keywords'])
```

---

## ğŸ“Š API Reference

### IntentAnalyzer
```python
analyzer = IntentAnalyzer()
intent = analyzer.analyze(query)

# Returns Intent:
#   - keywords: List[str]
#   - query_type: QueryType (CHAT, MEMORY_QUERY, TASK_REQUEST, TASK_UPDATE)
#   - confidence: float (0.0-1.0)
```

### LatticeCrawler
```python
crawler = LatticeCrawler(storage, max_days_back=7)
context = crawler.retrieve_context(intent, day_id, max_results=5)

# Returns RetrievedContext:
#   - contexts: List[Dict] - Relevant snippets with scores
#   - active_tasks: List[TaskState] - Current tasks
#   - sources: List[str] - Day IDs where context found
```

### MetadataExtractor
```python
extractor = MetadataExtractor(fallback_to_simple=True)
reply, metadata = extractor.parse_response(llm_output)

# Returns tuple:
#   - reply: str - Clean user-facing text
#   - metadata: dict with:
#       - keywords: List[str]
#       - summary: str
#       - affect: str
#       - parsing_method: 'structured' or 'fallback'
```

---

## ğŸ¯ LLM System Prompt Format

```
==USER_REPLY_START==
Your natural language response here
==USER_REPLY_END==

==METADATA_START==
KEYWORDS: keyword1, keyword2, keyword3
SUMMARY: One-line summary of this turn
AFFECT: neutral|positive|negative|curious|frustrated|excited|confused|satisfied
==METADATA_END==
```

**Import the prompt:**
```python
from memory.metadata_extractor import MEMORY_SYSTEM_PROMPT
```

---

## ğŸ§ª Testing Commands

```powershell
# Test crawler (5 comprehensive tests)
python test_crawler.py

# Test metadata extraction
python memory/metadata_extractor.py

# Test intent analyzer
python memory/retrieval/intent_analyzer.py

# Inspect database
python inspect_memory.py

# Run main with memory
python main.py
```

---

## ğŸ“ File Structure

```
memory/
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler.py           âœ… Search engine (324 lines)
â”‚   â””â”€â”€ intent_analyzer.py   âœ… Keyword extraction (243 lines)
â”œâ”€â”€ metadata_extractor.py    âœ… LLM parser (421 lines)
â”œâ”€â”€ storage.py               âœ… Database (900 lines)
â”œâ”€â”€ conversation_manager.py  âœ… Turn logging (260 lines)
â”œâ”€â”€ models.py                âœ… Data structures (475 lines)
â””â”€â”€ __init__.py

tests/
â””â”€â”€ test_crawler.py          âœ… Test suite (308 lines)

docs/
â”œâ”€â”€ INTEGRATION_GUIDE.md     ğŸ“„ Step-by-step integration
â”œâ”€â”€ PHASE_2_COMPLETE.md      ğŸ“„ Full component reference
â”œâ”€â”€ RETRIEVAL_SYSTEM_PLAN.md ğŸ“„ Design rationale
â””â”€â”€ FLOWCHART_ALIGNMENT_ANALYSIS.md ğŸ“„ Progress tracking
```

---

## âš™ï¸ Configuration Options

```python
# Crawler settings
crawler = LatticeCrawler(
    storage=storage,
    max_days_back=7  # How many days to search backward
)

# Retrieval settings
context = crawler.retrieve_context(
    intent=intent,
    current_day_id=today,
    max_results=5  # Top N results to return
)

# Metadata extraction
extractor = MetadataExtractor(
    fallback_to_simple=True  # Auto-fallback if parsing fails
)

# Intent analyzer
analyzer = IntentAnalyzer(
    use_llm_mode=False  # True to parse LLM-provided metadata
)
```

---

## âœ… Success Indicators

After integration, you should see:

1. **Console Output:**
   ```
   ğŸ” Intent: memory_query, Keywords: ['discuss', 'memory', 'systems']
   ğŸ“… Search range: 7 days (2025-10-10 to 2025-10-04)
   ğŸ“ Found 3 keyword matches
   âœ… Retrieved context: 3 snippets, 2 sources
   âœ… Metadata extracted: 5 keywords
   ```

2. **Database (inspect_memory.py):**
   - Keywords saved for each turn
   - Multiple sessions linked to same day
   - Full conversation text persisted

3. **User Experience:**
   - Clean responses (no visible metadata)
   - Context from past sessions retrieved
   - Relevant information recalled

---

## âš ï¸ Troubleshooting

| Problem | Solution |
|---------|----------|
| **No contexts retrieved** | â€¢ Check keywords are being saved (run `inspect_memory.py`)<br>â€¢ Verify crawler is initialized<br>â€¢ Check day_id format is YYYY-MM-DD |
| **Always fallback mode** | â€¢ LLM not outputting delimiters<br>â€¢ Check MEMORY_SYSTEM_PROMPT is in prompt<br>â€¢ Verify LLM can follow structured format |
| **Import errors** | â€¢ Check `memory/__init__.py` exports<br>â€¢ Verify file paths are correct<br>â€¢ Try standalone tests first |
| **Database errors** | â€¢ Check database path exists<br>â€¢ Verify Storage initialized<br>â€¢ Check file permissions |
| **Low relevance scores** | â€¢ Add more test data<br>â€¢ Tune scoring weights in crawler<br>â€¢ Use more specific keywords |

---

## ğŸ’¡ Tips & Best Practices

### **1. Progressive Enhancement**
Start simple, enhance later:
```python
# Week 1: Basic retrieval
context = crawler.retrieve_context(intent, today)

# Week 2: Add sliding window check
if not sliding_window.has_topic(intent.keywords):
    context = crawler.retrieve_context(intent, today)

# Week 3: Add context hydration
context = hydrator.build_prompt(sliding_window, context)
```

### **2. Monitor Metadata Quality**
```python
# Track structured vs fallback ratio
if metadata['parsing_method'] == 'structured':
    structured_count += 1
else:
    fallback_count += 1

# Log ratio for tuning
print(f"Structured: {structured_count}, Fallback: {fallback_count}")
```

### **3. Context Formatting**
```python
# Simple version
context_str = "\n".join([c['context'] for c in contexts])

# Enhanced version
context_str = ""
for ctx in contexts[:5]:
    context_str += f"\n[{ctx['day_id']}] {ctx['keyword']}: {ctx['context'][:100]}"
```

### **4. Error Handling**
```python
try:
    context = crawler.retrieve_context(intent, today)
except Exception as e:
    print(f"âš ï¸ Retrieval failed: {e}")
    context = RetrievedContext()  # Empty context
```

---

## ğŸ¯ Next Steps

### **This Week:**
1. [ ] Add imports to main.py
2. [ ] Initialize components
3. [ ] Modify conversation loop
4. [ ] Test with real queries
5. [ ] Monitor metadata quality

### **Next Week (Phase 3):**
6. [ ] Build SlidingWindow class
7. [ ] Add "already loaded" check
8. [ ] Implement topic tracking
9. [ ] Build context_hydrator.py

### **Week 3 (Phase 4):**
10. [ ] Day synthesis
11. [ ] Task integration
12. [ ] End-of-day processing

---

## ğŸ“š Documentation

- **INTEGRATION_GUIDE.md** - Complete integration walkthrough
- **PHASE_2_COMPLETE.md** - Full Phase 2 summary
- **RETRIEVAL_SYSTEM_PLAN.md** - Design decisions & rationale  
- **FLOWCHART_ALIGNMENT_ANALYSIS.md** - Progress tracking

---

## ğŸ‰ Current Status

**âœ… Phase 1 COMPLETE:** Storage, Models, Turn Logging  
**âœ… Phase 2 COMPLETE:** Retrieval, Intent Analysis, Metadata Extraction  
**âš ï¸ Phase 3 NEXT:** Sliding Window, Context Hydration, Integration  
**ğŸ”µ Phase 4 FUTURE:** Day Synthesis, Task Migration

---

## Import Everything

```python
from memory import (
    # Types
    TaskStatus, TaskType, QueryType, ContextSourceType,
    
    # Core Models  
    DayNode, Keyword, Summary, Affect, TaskState,
    
    # Retrieval
    Intent, RetrievedContext,
    
    # Conversation
    ConversationTurn, SlidingWindow,
    
    # Storage & Management
    Storage, ConversationManager,
    
    # Utils
    create_day_id, create_task_id
)

# Retrieval Components
from memory.retrieval.crawler import LatticeCrawler
from memory.retrieval.intent_analyzer import IntentAnalyzer

# Metadata Extraction
from memory.metadata_extractor import MetadataExtractor, MEMORY_SYSTEM_PROMPT
```
)
```

## Common Patterns

### Create a Day
```python
from datetime import datetime

day = DayNode(
    day_id=create_day_id(),
    created_at=datetime.now(),
    session_ids=["session_20251010_120000"]
)
```

### Create a Task
```python
task = TaskState(
    task_id=create_task_id(TaskType.RECURRING_PLAN),
    task_type=TaskType.RECURRING_PLAN,
    status=TaskStatus.ACTIVE,
    created_date=create_day_id(),
    created_at=datetime.now(),
    last_updated=datetime.now(),
    task_title="30-day rowing challenge",
    total_steps=30,
    completed_steps=7
)

# Check progress
if task.progress_percentage() >= 50:
    print("Halfway there!")
```

### Track Keywords
```python
keyword = Keyword(
    keyword="rowing",
    first_mentioned=datetime.now(),
    last_mentioned=datetime.now(),
    turn_ids=[1]
)

# Later, when mentioned again
keyword.increment(turn_id=5)
```

### Analyze Intent
```python
intent = Intent(
    keywords=["rowing", "progress", "how"],
    query_type=QueryType.TASK_UPDATE,
    confidence=0.85,
    primary_topics=["rowing"]
)
```

### Manage Sliding Window
```python
window = SlidingWindow(max_turns=20)

if not window.is_topic_active("rowing"):
    # Need to retrieve rowing context
    window.mark_topic_active("rowing")
else:
    # Already have rowing context
    pass
```

### Build Retrieved Context
```python
context = RetrievedContext()

# Add from day keywords
context.add_context(
    {"date": "2025-10-03", "content": "Started rowing"},
    source="day_keyword"
)

# Add active tasks
context.active_tasks.append(task)

# Check size
print(f"Total snippets: {len(context.contexts)}")
print(f"Sources: {context.sources}")
```

## Enum Values

### TaskStatus
- `TaskStatus.ACTIVE`
- `TaskStatus.PAUSED`
- `TaskStatus.COMPLETED`
- `TaskStatus.CANCELLED`

### TaskType
- `TaskType.DISCRETE`
- `TaskType.RECURRING_PLAN`
- `TaskType.ONGOING_COMMITMENT`

### QueryType
- `QueryType.CHAT`
- `QueryType.TASK_REQUEST`
- `QueryType.TASK_UPDATE`
- `QueryType.MEMORY_QUERY`

## Useful Methods

### TaskState
- `task.progress_percentage()` â†’ float (0-100)
- `task.to_dict()` â†’ dict

### Keyword
- `keyword.increment(turn_id)` â†’ Update frequency

### Affect
- `affect.update(turn_id, intensity, topics)` â†’ Update pattern

### RetrievedContext
- `context.add_context(data, source)` â†’ Add snippet

### SlidingWindow
- `window.is_topic_active(topic)` â†’ bool
- `window.mark_topic_active(topic)` â†’ None
- `window.add_turn(turn)` â†’ None (auto-prunes if needed)

## Integration with Existing Code

```python
# Your existing code
from core.cognitive_lattice import CognitiveLattice

lattice = CognitiveLattice()
print(f"Session: {lattice.session_id}")

# New memory models
from memory import DayNode, create_day_id

day = DayNode(
    day_id=create_day_id(),
    created_at=datetime.now(),
    session_ids=[lattice.session_id]
)

# They work together!
print(f"Today: {day.day_id}")
print(f"Session: {lattice.session_id}")
```

## Testing

```bash
# Test models directly
python memory/models.py

# Test package imports
python -c "from memory import DayNode; print('Works!')"

# Test with existing system
python -c "from core.cognitive_lattice import CognitiveLattice; from memory import TaskState; print('Compatible!')"
```

## Next Steps

After `storage.py` is created:
```python
from memory.storage import Storage

storage = Storage("memory.db")
storage.save_day(day)
storage.save_task(task)

loaded_day = storage.get_day("2025-10-10")
```
